{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c874cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c4b0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data you cleaned in the EDA notebook\n",
    "fraud_df = pd.read_csv('../data/processed/fraud_data_with_country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110d81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Time-based features [cite: 111]\n",
    "fraud_df['signup_time'] = pd.to_datetime(fraud_df['signup_time'])\n",
    "fraud_df['purchase_time'] = pd.to_datetime(fraud_df['purchase_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "022d0745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time difference in seconds [cite: 114]\n",
    "fraud_df['time_since_signup'] = (fraud_df['purchase_time'] - fraud_df['signup_time']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7084ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time difference in seconds [cite: 114]\n",
    "fraud_df['time_since_signup'] = (fraud_df['purchase_time'] - fraud_df['signup_time']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fca6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Transaction frequency and velocity [cite: 110]\n",
    "# Count how many times the same device was used\n",
    "fraud_df['device_usage_count'] = fraud_df.groupby('device_id')['device_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df6ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times the same IP was used\n",
    "fraud_df['ip_usage_count'] = fraud_df.groupby('ip_address')['ip_address'].transform('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a2e02",
   "metadata": {},
   "source": [
    "Data Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6bfafef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Categorical Encoding (One-Hot Encoding) [cite: 117]\n",
    "# We encode features like source and browser\n",
    "fraud_df = pd.get_dummies(fraud_df, columns=['source', 'browser', 'sex'], drop_first=True)\n",
    "\n",
    "# 4. Normalization/Scaling [cite: 116]\n",
    "scaler = StandardScaler()\n",
    "num_features = ['purchase_value', 'age', 'time_since_signup', 'device_usage_count', 'ip_usage_count']\n",
    "fraud_df[num_features] = scaler.fit_transform(fraud_df[num_features])\n",
    "\n",
    "# For the Bank dataset, scale the 'Amount' feature [cite: 44]\n",
    "# credit_df['Amount'] = scaler.fit_transform(credit_df[['Amount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede0759",
   "metadata": {},
   "source": [
    "Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d66356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE:\n",
      " class\n",
      "0    136961\n",
      "1     14151\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After SMOTE:\n",
      " class\n",
      "0    136961\n",
      "1    136961\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate features from target [cite: 127, 129]\n",
    "X = fraud_df.drop(['class', 'user_id', 'signup_time', 'purchase_time', 'device_id', 'country'], axis=1)\n",
    "y = fraud_df['class']\n",
    "\n",
    "# Document distribution before SMOTE [cite: 121]\n",
    "print(\"Before SMOTE:\\n\", y.value_counts())\n",
    "\n",
    "# Apply SMOTE \n",
    "# Note: In a real workflow, you should split your data FIRST and only apply SMOTE to the training set.\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Document distribution after SMOTE [cite: 121]\n",
    "print(\"\\nAfter SMOTE:\\n\", pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d20f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the processed data folder\n",
    "X_resampled.to_csv('../data/processed/fraud_features.csv', index=False)\n",
    "pd.Series(y_resampled).to_csv('../data/processed/fraud_target.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
